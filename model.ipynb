{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455,)\n",
      "(7172,)\n",
      "(27455, 28, 28, 1)\n",
      "(7172, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#a little data preprocessing\n",
    "\n",
    "train = pd.read_csv(\"sign_mnist_train.csv\")\n",
    "test = pd.read_csv(\"sign_mnist_test.csv\")\n",
    "\n",
    "y_train = train['label']\n",
    "y_test = test['label']\n",
    "del train['label']\n",
    "del test['label']\n",
    "\n",
    "# convert to numpy rep for keras\n",
    "x_train = train.values\n",
    "x_test = test.values \n",
    "y_train = y_train.values\n",
    "y_test = y_test.values \n",
    "\n",
    "# normalization and change to gray scale\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# reshape \n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "# find all unique labels: data for 9(J) and 25(Z) are missing\n",
    "labels = np.array(np.unique(y_test))\n",
    "numLabels = 24\n",
    "print(labels)\n",
    "\n",
    "# one hot encode the labels \n",
    "# for train set\n",
    "ohe_labels_train = np.zeros((len(y_train), numLabels))\n",
    "for i in range (len(y_train)):\n",
    "    ohe_labels_train[i] = np.where(labels == y_train[i], 1, 0)\n",
    "\n",
    "# for test set\n",
    "ohe_labels_test = np.zeros((len(y_test), numLabels))\n",
    "for i in range (len(y_test)):\n",
    "    ohe_labels_test[i] = np.where(labels == y_test[i], 1, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x267a9ed6880>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot an image \n",
    "plt.imshow(x_train[1], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 25)        250       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 25)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 25)        5650      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 25)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          5650      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 7, 25)          0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                20050     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 50)               200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                1224      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,024\n",
      "Trainable params: 32,924\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# convolutional model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=25, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D((2,2), padding = 'same'))\n",
    "model.add(Conv2D(filters=25, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D((2,2), padding = 'same'))\n",
    "model.add(Conv2D(filters=25, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D((2,2), padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(24, activation='softmax'))\n",
    "\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "687/687 [==============================] - 22s 31ms/step - loss: 1.2228 - accuracy: 0.6702 - val_loss: 0.5722 - val_accuracy: 0.9135\n",
      "Epoch 2/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.1734 - accuracy: 0.9643 - val_loss: 0.1647 - val_accuracy: 0.9867\n",
      "Epoch 3/250\n",
      "687/687 [==============================] - 22s 33ms/step - loss: 0.0658 - accuracy: 0.9877 - val_loss: 0.0713 - val_accuracy: 0.9975\n",
      "Epoch 4/250\n",
      "687/687 [==============================] - 22s 32ms/step - loss: 0.0454 - accuracy: 0.9896 - val_loss: 0.1228 - val_accuracy: 0.9761\n",
      "Epoch 5/250\n",
      "687/687 [==============================] - 24s 35ms/step - loss: 0.0337 - accuracy: 0.9919 - val_loss: 0.0416 - val_accuracy: 0.9976\n",
      "Epoch 6/250\n",
      "687/687 [==============================] - 19s 28ms/step - loss: 0.0249 - accuracy: 0.9939 - val_loss: 0.0204 - val_accuracy: 0.9985\n",
      "Epoch 7/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0220 - val_accuracy: 0.9989\n",
      "Epoch 8/250\n",
      "687/687 [==============================] - 19s 28ms/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.0518 - val_accuracy: 0.9898\n",
      "Epoch 9/250\n",
      "687/687 [==============================] - 22s 32ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.0148 - val_accuracy: 0.9973\n",
      "Epoch 10/250\n",
      "687/687 [==============================] - 22s 32ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 11/250\n",
      "687/687 [==============================] - 22s 33ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0106 - val_accuracy: 0.9985\n",
      "Epoch 12/250\n",
      "687/687 [==============================] - 23s 34ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 13/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 14/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0136 - val_accuracy: 0.9971\n",
      "Epoch 15/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 16/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0790 - val_accuracy: 0.9767\n",
      "Epoch 17/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0081 - val_accuracy: 0.9982\n",
      "Epoch 18/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0296 - val_accuracy: 0.9927\n",
      "Epoch 19/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0069 - val_accuracy: 0.9996\n",
      "Epoch 20/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0110 - val_accuracy: 0.9989\n",
      "Epoch 21/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0133 - val_accuracy: 0.9967\n",
      "Epoch 22/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0074 - val_accuracy: 0.9989\n",
      "Epoch 23/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
      "Epoch 24/250\n",
      "687/687 [==============================] - 24s 34ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0132 - val_accuracy: 0.9980\n",
      "Epoch 25/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0079 - val_accuracy: 0.9980\n",
      "Epoch 26/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 27/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 28/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0364 - val_accuracy: 0.9902\n",
      "Epoch 29/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 30/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.0023 - val_accuracy: 0.9998\n",
      "Epoch 31/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "Epoch 32/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 33/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
      "Epoch 34/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0068 - val_accuracy: 0.9965\n",
      "Epoch 35/250\n",
      "687/687 [==============================] - 20s 28ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 36/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 37/250\n",
      "687/687 [==============================] - 19s 28ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 8.9208e-04 - val_accuracy: 0.9998\n",
      "Epoch 38/250\n",
      "687/687 [==============================] - 19s 28ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0028 - val_accuracy: 0.9998\n",
      "Epoch 39/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 40/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0037 - val_accuracy: 0.9996\n",
      "Epoch 41/250\n",
      "687/687 [==============================] - 22s 32ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
      "Epoch 42/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 43/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 44/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0025 - val_accuracy: 0.9996\n",
      "Epoch 45/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0085 - val_accuracy: 0.9978\n",
      "Epoch 46/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 7.9396e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 3.9750e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 49/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 8.9943e-04 - val_accuracy: 0.9998\n",
      "Epoch 50/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 8.9174e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 52/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 53/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 5.4388e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 2.4901e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0071 - val_accuracy: 0.9985\n",
      "Epoch 56/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0062 - val_accuracy: 0.9985\n",
      "Epoch 57/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0065 - accuracy: 0.9975 - val_loss: 6.9312e-04 - val_accuracy: 0.9998\n",
      "Epoch 58/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 9.1805e-04 - val_accuracy: 0.9998\n",
      "Epoch 59/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0021 - val_accuracy: 0.9996\n",
      "Epoch 60/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 8.6635e-04 - val_accuracy: 0.9998\n",
      "Epoch 61/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 62/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 63/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
      "Epoch 64/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 65/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 66/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 1.8519e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 68/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 69/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "Epoch 70/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0065 - val_accuracy: 0.9993\n",
      "Epoch 71/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 72/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 2.2500e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 74/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 75/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 2.7358e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 3.5260e-04 - val_accuracy: 0.9998\n",
      "Epoch 77/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 8.8377e-04 - val_accuracy: 0.9998\n",
      "Epoch 78/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "Epoch 79/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 80/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.6930e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.0259e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.1636e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 7.8606e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 85/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 4.6460e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "Epoch 87/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 88/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 89/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 1.6547e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 91/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 9.8077e-04 - val_accuracy: 0.9998\n",
      "Epoch 92/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 9.4846e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 1.5685e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "Epoch 95/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 3.1149e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 2.4234e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 1.9264e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
      "Epoch 99/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 100/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 7.7810e-04 - val_accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 3.1090e-04 - val_accuracy: 1.0000\n",
      "Epoch 102/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
      "Epoch 103/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 4.0827e-04 - val_accuracy: 1.0000\n",
      "Epoch 104/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 2.8956e-04 - val_accuracy: 1.0000\n",
      "Epoch 105/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 2.0620e-04 - val_accuracy: 1.0000\n",
      "Epoch 106/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 4.5683e-04 - val_accuracy: 1.0000\n",
      "Epoch 107/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 108/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
      "Epoch 109/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 5.7198e-04 - val_accuracy: 0.9998\n",
      "Epoch 110/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 6.6403e-04 - val_accuracy: 0.9996\n",
      "Epoch 111/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.6546e-04 - val_accuracy: 1.0000\n",
      "Epoch 112/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 2.7278e-04 - val_accuracy: 1.0000\n",
      "Epoch 113/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 7.8856e-04 - val_accuracy: 1.0000\n",
      "Epoch 114/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
      "Epoch 115/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0538 - val_accuracy: 0.9807\n",
      "Epoch 116/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
      "Epoch 117/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 3.5564e-04 - val_accuracy: 1.0000\n",
      "Epoch 118/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 119/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
      "Epoch 120/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 6.3128e-04 - val_accuracy: 1.0000\n",
      "Epoch 121/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
      "Epoch 122/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 7.4397e-04 - val_accuracy: 1.0000\n",
      "Epoch 123/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.6332e-04 - val_accuracy: 1.0000\n",
      "Epoch 124/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.1467e-04 - val_accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 126/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 9.7136e-04 - val_accuracy: 0.9998\n",
      "Epoch 127/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 2.9176e-04 - val_accuracy: 1.0000\n",
      "Epoch 128/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 7.2959e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 130/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 6.2654e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 8.7931e-04 - accuracy: 0.9998 - val_loss: 5.9254e-04 - val_accuracy: 0.9998\n",
      "Epoch 132/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 6.5759e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 3.7514e-04 - val_accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 3.1475e-04 - val_accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 4.7449e-04 - val_accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 1.2001e-04 - val_accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 1.0869e-04 - val_accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 6.3397e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 3.7465e-04 - val_accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 1.8845e-04 - val_accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
      "Epoch 142/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 4.8019e-05 - val_accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 3.7548e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.0094e-04 - val_accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "687/687 [==============================] - 20s 29ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 1.7621e-04 - val_accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 1.1601e-04 - val_accuracy: 1.0000\n",
      "Epoch 147/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 8.7543e-05 - val_accuracy: 1.0000\n",
      "Epoch 148/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 2.7764e-04 - val_accuracy: 1.0000\n",
      "Epoch 149/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "Epoch 150/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "Epoch 151/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 7.3663e-04 - val_accuracy: 0.9998\n",
      "Epoch 152/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 7.4735e-04 - val_accuracy: 0.9998\n",
      "Epoch 153/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 3.6471e-05 - val_accuracy: 1.0000\n",
      "Epoch 154/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 4.0633e-04 - val_accuracy: 0.9998\n",
      "Epoch 155/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 1.1311e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 9.6168e-04 - val_accuracy: 0.9996\n",
      "Epoch 157/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.1163e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "Epoch 159/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 6.1076e-05 - val_accuracy: 1.0000\n",
      "Epoch 160/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 161/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 5.5458e-05 - val_accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 6.9722e-04 - accuracy: 0.9998 - val_loss: 2.9306e-05 - val_accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.5817e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 4.8325e-04 - val_accuracy: 1.0000\n",
      "Epoch 165/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 9.3935e-04 - accuracy: 0.9997 - val_loss: 1.4043e-04 - val_accuracy: 1.0000\n",
      "Epoch 166/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.0973e-04 - val_accuracy: 1.0000\n",
      "Epoch 167/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 5.3243e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 4.5561e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.2115e-04 - val_accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 1.9312e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 7.9833e-04 - val_accuracy: 0.9996\n",
      "Epoch 172/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 7.1417e-04 - val_accuracy: 0.9998\n",
      "Epoch 173/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 2.6516e-04 - val_accuracy: 1.0000\n",
      "Epoch 174/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0026 - val_accuracy: 0.9989\n",
      "Epoch 175/250\n",
      "687/687 [==============================] - 21s 31ms/step - loss: 9.7221e-04 - accuracy: 0.9997 - val_loss: 6.0877e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 6.3071e-04 - val_accuracy: 0.9998\n",
      "Epoch 177/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.0405e-04 - val_accuracy: 1.0000\n",
      "Epoch 178/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "Epoch 179/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.5148e-04 - val_accuracy: 1.0000\n",
      "Epoch 180/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 6.6366e-04 - val_accuracy: 0.9996\n",
      "Epoch 181/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.8701e-04 - val_accuracy: 1.0000\n",
      "Epoch 182/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 6.0712e-04 - val_accuracy: 0.9998\n",
      "Epoch 183/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.0753e-04 - val_accuracy: 0.9998\n",
      "Epoch 184/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 5.8084e-04 - val_accuracy: 0.9998\n",
      "Epoch 185/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 8.7704e-05 - val_accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.7215e-04 - val_accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 5.8357e-04 - val_accuracy: 0.9998\n",
      "Epoch 188/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 189/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 190/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 9.1612e-04 - val_accuracy: 0.9996\n",
      "Epoch 191/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 1.5422e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 8.7358e-04 - accuracy: 0.9997 - val_loss: 0.0110 - val_accuracy: 0.9956\n",
      "Epoch 193/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 4.7010e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 1.1795e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 2.7741e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 6.5204e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 5.8310e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 6.7794e-04 - accuracy: 0.9997 - val_loss: 8.3430e-05 - val_accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 6.8390e-04 - val_accuracy: 0.9998\n",
      "Epoch 200/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.0705e-04 - val_accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 5.0722e-05 - val_accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0083 - val_accuracy: 0.9973\n",
      "Epoch 203/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 2.0897e-04 - val_accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 3.0679e-04 - val_accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.9352e-04 - val_accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 6.0756e-05 - val_accuracy: 1.0000\n",
      "Epoch 207/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 5.0534e-04 - val_accuracy: 0.9998\n",
      "Epoch 208/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.6670e-05 - val_accuracy: 1.0000\n",
      "Epoch 209/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 9.9928e-04 - accuracy: 0.9996 - val_loss: 8.5010e-05 - val_accuracy: 1.0000\n",
      "Epoch 210/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 211/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.5322e-04 - val_accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 9.9266e-05 - val_accuracy: 1.0000\n",
      "Epoch 213/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.9791e-04 - val_accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 8.4836e-04 - accuracy: 0.9998 - val_loss: 2.2254e-04 - val_accuracy: 1.0000\n",
      "Epoch 215/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 8.7833e-05 - val_accuracy: 1.0000\n",
      "Epoch 216/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 6.8070e-05 - val_accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.6411e-04 - val_accuracy: 1.0000\n",
      "Epoch 218/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.4275e-04 - val_accuracy: 1.0000\n",
      "Epoch 219/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 3.6694e-04 - val_accuracy: 1.0000\n",
      "Epoch 220/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 1.1932e-04 - val_accuracy: 1.0000\n",
      "Epoch 221/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 8.4682e-05 - val_accuracy: 1.0000\n",
      "Epoch 222/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.8097e-04 - val_accuracy: 1.0000\n",
      "Epoch 223/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 224/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 2.7541e-04 - val_accuracy: 1.0000\n",
      "Epoch 225/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 2.0677e-05 - val_accuracy: 1.0000\n",
      "Epoch 226/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 3.0198e-05 - val_accuracy: 1.0000\n",
      "Epoch 227/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 7.5651e-05 - val_accuracy: 1.0000\n",
      "Epoch 228/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 8.0765e-04 - accuracy: 0.9998 - val_loss: 1.2340e-05 - val_accuracy: 1.0000\n",
      "Epoch 229/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.3513e-04 - val_accuracy: 1.0000\n",
      "Epoch 230/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 5.6781e-04 - accuracy: 0.9998 - val_loss: 1.0772e-04 - val_accuracy: 1.0000\n",
      "Epoch 231/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.1532e-04 - val_accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 4.7975e-05 - val_accuracy: 1.0000\n",
      "Epoch 233/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 5.3223e-05 - val_accuracy: 1.0000\n",
      "Epoch 234/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 5.0892e-04 - val_accuracy: 0.9998\n",
      "Epoch 235/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 3.6363e-05 - val_accuracy: 1.0000\n",
      "Epoch 236/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 3.9737e-04 - val_accuracy: 0.9998\n",
      "Epoch 237/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 2.5324e-05 - val_accuracy: 1.0000\n",
      "Epoch 238/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 1.1850e-04 - val_accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 240/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 4.3239e-05 - val_accuracy: 1.0000\n",
      "Epoch 241/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 8.3762e-04 - accuracy: 0.9996 - val_loss: 1.1859e-04 - val_accuracy: 1.0000\n",
      "Epoch 242/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.3212e-04 - val_accuracy: 1.0000\n",
      "Epoch 243/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 3.5192e-04 - val_accuracy: 0.9998\n",
      "Epoch 244/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 2.7163e-04 - val_accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 2.3576e-04 - val_accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 8.4493e-05 - val_accuracy: 1.0000\n",
      "Epoch 247/250\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 9.4701e-04 - accuracy: 0.9997 - val_loss: 2.7428e-04 - val_accuracy: 1.0000\n",
      "Epoch 248/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 7.9511e-04 - val_accuracy: 0.9998\n",
      "Epoch 249/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.4737e-05 - val_accuracy: 1.0000\n",
      "Epoch 250/250\n",
      "687/687 [==============================] - 20s 30ms/step - loss: 3.8369e-04 - accuracy: 0.9999 - val_loss: 3.8698e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(x_train, ohe_labels_train, validation_split=0.2, epochs=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training.history['loss'])\n",
    "plt.plot(training.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 6ms/step - loss: 0.1452 - accuracy: 0.9706\n",
      "Test accuracy: 0.9705800414085388\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, ohe_labels_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac81dd28b25742b4a884ea6ee71296b40f33b9dfeca96ce2595bdd92274cb316"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('tfenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
